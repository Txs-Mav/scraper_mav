# Scraper AI - Approche bas√©e sur l'analyse HTML par Gemini

Cette nouvelle approche utilise Gemini pour analyser le HTML d'un site web et g√©n√©rer automatiquement un scraper Python sp√©cifique pour chaque site. Les scrapers g√©n√©r√©s sont mis en cache pour une r√©utilisation future.

## Fonctionnalit√©s principales

### üîç Analyse intelligente multi-pages
Gemini analyse d'abord la page d'accueil et d√©cide intelligemment si d'autres pages sont n√©cessaires pour comprendre la structure compl√®te du site:
- Pages de listing de produits (inventaire, catalogue)
- Pages de d√©tail d'un produit
- Pages de contact pour les informations entreprise
- Pages de cat√©gories si structures diff√©rentes

### ü§ñ G√©n√©ration automatique de scraper
- Cr√©e un code Python complet et fonctionnel pour chaque site
- S√©lecteurs CSS/XPath pr√©cis bas√©s sur l'analyse du HTML
- Gestion automatique de tous les champs du sch√©ma

### üíæ Cache intelligent
- Les scrapers g√©n√©r√©s sont sauvegard√©s et r√©utilis√©s automatiquement
- Option pour forcer la r√©g√©n√©ration si n√©cessaire
- Option pour invalider le cache d'un site

### üìë Gestion de pagination
D√©tecte et g√®re automatiquement tous les types de pagination:
- Pagination par URL (?page=2)
- Bouton "Suivant"
- Scroll infini (d√©tection)
- Limite de s√©curit√© automatique

### ‚ö° Scraping parall√®le
- Tous les sites sont scrap√©s simultan√©ment
- Max 4 sites en parall√®le pour √©viter la surcharge

### üí∞ Comparaison de prix intelligente
- Seuls les produits pr√©sents chez le concurrent ET le site de r√©f√©rence sont affich√©s
- Matching par : marque + mod√®le + ann√©e
- Diff√©rence de prix calcul√©e automatiquement

## Structure

```
scraper_ai/
‚îú‚îÄ‚îÄ __init__.py              # Package Python
‚îú‚îÄ‚îÄ config.py                # Configuration et sch√©mas
‚îú‚îÄ‚îÄ gemini_client.py         # Client pour les appels Gemini API
‚îú‚îÄ‚îÄ html_analyzer.py         # Analyse HTML et g√©n√©ration de scraper (multi-pages)
‚îú‚îÄ‚îÄ scraper_executor.py      # Ex√©cution des scrapers g√©n√©r√©s
‚îú‚îÄ‚îÄ main.py                  # Point d'entr√©e principal
‚îî‚îÄ‚îÄ README.md                # Ce fichier
```

## Utilisation

### Scraper un seul site

Pour scraper un seul site sans comparaison de prix :

**Depuis le r√©pertoire parent du projet** (`/scraper_mav/`) :
```bash
python -m scraper_ai.main https://www.mvmmotosport.com/fr/
```

**Depuis le r√©pertoire `scraper_ai/`** :
```bash
python main.py https://www.mvmmotosport.com/fr/
```

Le scraper va :
1. Analyser le site et g√©n√©rer un scraper Python sp√©cifique
2. Sauvegarder le scraper dans le cache (`scraper_cache/`)
3. Ex√©cuter le scraper pour extraire tous les produits
4. Sauvegarder les r√©sultats dans `scraped_data.json`

### Scraper avec comparaison de prix

Pour comparer les prix avec un site de r√©f√©rence :

**Depuis le r√©pertoire parent** :
```bash
python -m scraper_ai.main --reference https://mvmmotosport.com/fr/ https://concurrent1.com https://concurrent2.com
```

**Depuis le r√©pertoire `scraper_ai/`** :
```bash
python main.py --reference https://mvmmotosport.com/fr/ https://concurrent1.com https://concurrent2.com
```

### Forcer la r√©g√©n√©ration des scrapers

Pour r√©g√©n√©rer un scraper m√™me s'il existe d√©j√† dans le cache :

**Depuis le r√©pertoire parent** :
```bash
python -m scraper_ai.main --force-refresh https://site1.com https://site2.com
```

**Depuis le r√©pertoire `scraper_ai/`** :
```bash
python main.py --force-refresh https://site1.com https://site2.com
```

### Invalider le cache

Pour supprimer le cache d'un site sp√©cifique :

**Depuis le r√©pertoire parent** :
```bash
python -m scraper_ai.main --invalidate-cache https://site.com
```

**Depuis le r√©pertoire `scraper_ai/`** :
```bash
python main.py --invalidate-cache https://site.com
```

## Comment √ßa fonctionne

### √âtape 1: R√©cup√©ration de la page d'accueil
Le syst√®me r√©cup√®re le contenu HTML de la page d'accueil du site.

### √âtape 2: Analyse et s√©lection de pages
Gemini analyse la page d'accueil et d√©cide intelligemment si d'autres pages sont n√©cessaires.

### √âtape 3: G√©n√©ration du scraper
Avec tout le contexte des pages analys√©es, Gemini g√©n√®re un code Python complet.

### √âtape 4: Mise en cache
Le scraper g√©n√©r√© est sauvegard√© dans `scraper_cache/` pour r√©utilisation.

### √âtape 5: Ex√©cution parall√®le
Tous les sites sont scrap√©s en parall√®le.

### √âtape 6: Comparaison
Seuls les produits avec correspondance dans le site de r√©f√©rence sont conserv√©s.

## Cache

Les scrapers g√©n√©r√©s sont mis en cache dans le dossier `scraper_cache/` √† la racine du projet.

- Chaque site a un fichier de cache unique bas√© sur son domaine
- Utilisez `--force-refresh` pour r√©g√©n√©rer un scraper
- Utilisez `--invalidate-cache` pour supprimer le cache

## Estimation du temps

- ~30s par site en cache
- ~90s par nouveau site (analyse + g√©n√©ration)

